Big O notation
===
From [Wikipedia, the free encyclopedia](https://en.wikipedia.org/wiki/Big_O_notation)

>In [computer science](https://en.wikipedia.org/wiki/Computer_science), 
>big O notation is used to [classify algorithms](https://en.wikipedia.org/wiki/Computational_complexity_theory) 
>according to how their run time or space requirements grow as the input size grows.[3] 
>In [analytic number theory](https://en.wikipedia.org/wiki/Analytic_number_theory), 
>big O notation is often used to express a bound on the difference between an arithmetical 
>function and a better understood approximation; a famous example of such a difference is 
>the remainder term in the [prime number theorem](https://en.wikipedia.org/wiki/Prime_number_theorem).
